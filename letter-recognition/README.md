# letter-recognizer
Recognition of the letters A through E from distorted patterns via Discrete Hopfield Neural Network Model. This project is a part of the EE550 Artificial Neural Networks course offered at Boğaziçi University.

## Limitations and Concerns
Since the network is highly nonlinear, there are multiple local minimums where the sample
patterns lie, in the energy function. Carelessly playing with the sample letters may cause these
patterns overlap and merge the local minimums. This may lead the network to converge to a
spurious state. For this reason, the sample patterns were designed manually and fine-tuned to
avoid the output to converge to a false or spurious state.
Furthermore, adding too much noise, for instance noise whose sigma > 1.2 for the sample
patterns used in this program, might cause the inputs not to be around the vicinity of the
desired local minimum. These inputs may eventually fall into another sample pattern’s local
minimum; or even a weird combination of the two patterns, say, a spurious state. The sample
patterns created for this program generally handle sigma < 1.2. without any problem. With
the purposes of scalability and flexibility, the sigma values and their corresponding number of
iterations were stored in arrays,
```
sigmaVals = [0.4 0.6 0.8]';
num_iter = [2 2 2]'; %The array indices match to the sigma values.
```
With this setting, if the user desires to change the sample patterns, thus the shape of the energy
function, the distortion levels will not be a problem since it is possible to test with any sigma
value with any number of iterations. Also, this setting will help the user to gauge the new
sample pattern’s efficiency in a faster manner.


## Approach and Methodology
The letters A, B, C, D, E was created by 1’s and 0’s in 8x8x5 matrix whose first two dimensions
are for the grid while the third one stands for the number of letters. These are, then, visualized
in five plots under the same figure. In the visualization the colormap was reduced to include
only black and white to represent 1 and 0, respectively.
The data must be in the proper form for learning. To do this, the 8x8x5 grid representation
was converted to 64x5 matrix whose rows are the actual patterns. On the other hand, since
the model uses bipolar form, all the 0’s were transformed into -1’s. The model arranges the
weights with multiplying each neuron with other neurons and repeats this process for multiple
samples. Since each neuron does not interact with itself, the diagonals in the T matrix are zero.
Thus, the following vectorized relation,

<a href="https://www.codecogs.com/eqnedit.php?latex=XX^T&space;-&space;aI" target="_blank"><img src="https://latex.codecogs.com/gif.latex?XX^T&space;-&space;aI" title="XX^T - aI" /></a>

where T is the weight matrix, x is the sample patterns, a is the number of patterns and I is
the identity matrix, is used to implement the learning phase.
To test the algorithm noises are added to the input vectors. It was generated by random
variables taken from Gaussian distribution with 0 mean and three different sigma values. For
convenience, the sigma values are chosen as 0.4, 0.6 and 0.8. For each sigma value, the program
calculates a 64x5 noise matrix whose columns corresponds to each sample pattern. Adding the
noise, the program visualizes the distorted inputs. Then, the model is updated with two
iterations and finally it is demonstrated that these noisy patterns converges to the original
samples.

## Design Decisions
Since there are too many resulting plots, it was important for analysis that these plots appear
neatly and orderly. Furthermore, it was equally important that the user understands what is
happening and catches up with the program for comfort. Toward that end, in certain
checkpoints, the program was designed to interact with the user. In fact, it prints information 
Mehmet Yaşar Alıcı - 2016401378
about its progress, pauses and prompts the user to continue during interfacing. Also, the titles
and subtitles were made explanatorily for a better analysis.
In the implementation of the model, loops are avoided and vectorized multiplications were
preferred for efficiency and readability. Also, if it is desired to model the noise with intermediate
colors; it is also possible to plug some colors in to the map array, found in visualization.m,
```
map = [1 1 1
 0 0 0
 ];
 ```
[1 1 1] stands for white while [0 0 0] is for black. For addition of colors, 
[this link](https://www.tug.org/pracjourn/2007-4/walden/color.pdf/) 
can be referred to
for all the RGB Triplets.

## Authors
- Mehmet Yaşar Alıcı - [myasaralici](github.com/myasaralici)

## License
This project is licensed under the MIT License - see the LICENSE.md file for details


